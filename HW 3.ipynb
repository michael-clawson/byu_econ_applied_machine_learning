{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join('C:\\\\Users\\\\michael.clawson\\\\Desktop\\School\\\\Machine Learning\\\\Titanic\\\\train.csv'))\n",
    "test = pd.read_csv(os.path.join('C:\\\\Users\\\\michael.clawson\\\\Desktop\\School\\\\Machine Learning\\\\Titanic\\\\test.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see in here that we are dealing with a rather complete dataset, barring a couple of values, specifically age and cabin number. Additionally, there are several parts of our dataframe that are likely not terribly useful. For example, there is little chance that the ticket number would correspond to survival rates, outside of how it relates to where the cabin is located. Let us now look at the survival rate of the training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.616162\n",
       "1    0.383838\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Survived'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x231c66aec18>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x231c66a1c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(train['Survived'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now examine the Pclass variable: this will be categorical, and a higher-class ticket correlates quite highly with elevated rates of survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass\n",
       "1    0.629630\n",
       "2    0.472826\n",
       "3    0.242363\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Survived'].groupby(train['Pclass']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x231c66b7e10>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlQEhSWplQEiSWhkQkqRW/x/zC6WRyZEB0AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x231c3eafb38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(train['Pclass'], hue=train['Survived'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Name variable is not very useful at first glance, however it may prove interesting to separate the titles associated with those names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr.          517\n",
       "Miss.        182\n",
       "Mrs.         125\n",
       "Master.       40\n",
       "Dr.            7\n",
       "Rev.           6\n",
       "Major.         2\n",
       "Mlle.          2\n",
       "Col.           2\n",
       "Ms.            1\n",
       "the            1\n",
       "Don.           1\n",
       "Lady.          1\n",
       "Sir.           1\n",
       "Jonkheer.      1\n",
       "Capt.          1\n",
       "Mme.           1\n",
       "Name: Name_Title, dtype: int64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Name_Title'] = train['Name'].apply(lambda x: x.split(',')[1]).apply(lambda x: x.split()[0])\n",
    "train['Name_Title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name_Title\n",
       "Capt.        0.000000\n",
       "Col.         0.500000\n",
       "Don.         0.000000\n",
       "Dr.          0.428571\n",
       "Jonkheer.    0.000000\n",
       "Lady.        1.000000\n",
       "Major.       0.500000\n",
       "Master.      0.575000\n",
       "Miss.        0.697802\n",
       "Mlle.        1.000000\n",
       "Mme.         1.000000\n",
       "Mr.          0.156673\n",
       "Mrs.         0.792000\n",
       "Ms.          1.000000\n",
       "Rev.         0.000000\n",
       "Sir.         1.000000\n",
       "the          1.000000\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Survived'].groupby(train['Name_Title']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to see that this new variable, a partial amalgam of age and gender, shows what we would expect: Being a woman or a child makes one much more likely to survive. Also, at the time those of higher socioeconomic status generally had longer names than those in the lower classes. We see this correlation below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name_Len\n",
       "(11.999, 19.0]    0.220588\n",
       "(19.0, 23.0]      0.301282\n",
       "(23.0, 27.0]      0.319797\n",
       "(27.0, 32.0]      0.442424\n",
       "(32.0, 82.0]      0.674556\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Name_Len'] = train['Name'].apply(lambda x: len(x))\n",
    "train['Survived'].groupby(pd.qcut(train['Name_Len'],5)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11.999, 19.0]    204\n",
       "(23.0, 27.0]      197\n",
       "(32.0, 82.0]      169\n",
       "(27.0, 32.0]      165\n",
       "(19.0, 23.0]      156\n",
       "Name: Name_Len, dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.qcut(train['Name_Len'],5).value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sex is a very useful metric in this dataset, and as expected, women were much more likely to survive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex\n",
       "female    0.742038\n",
       "male      0.188908\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Sex'].value_counts(normalize=True)\n",
    "train['Survived'].groupby(train['Sex']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to fill in with the age of the null values, but first it is interesting to note that those with no age listed were not as likely to survive as those with ages in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age\n",
       "False    0.406162\n",
       "True     0.293785\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Survived'].groupby(train['Age'].isnull()).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first glance it seems that age had little to do with survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age\n",
       "(0.419, 19.0]    0.481707\n",
       "(19.0, 25.0]     0.328467\n",
       "(25.0, 31.8]     0.393701\n",
       "(31.8, 41.0]     0.437500\n",
       "(41.0, 80.0]     0.373239\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Survived'].groupby(pd.qcut(train['Age'],5)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.419, 19.0]    164\n",
       "(31.8, 41.0]     144\n",
       "(41.0, 80.0]     142\n",
       "(19.0, 25.0]     137\n",
       "(25.0, 31.8]     127\n",
       "Name: Age, dtype: int64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.qcut(train['Age'],5).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sibsp (Number of siblings/spouses) shows a spurious relationship at best, except where more family members and siblings could be a proxy here for lower socioeconomic status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SibSp\n",
       "0    0.345395\n",
       "1    0.535885\n",
       "2    0.464286\n",
       "3    0.250000\n",
       "4    0.166667\n",
       "5    0.000000\n",
       "8    0.000000\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Survived'].groupby(train['SibSp']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    608\n",
       "1    209\n",
       "2     28\n",
       "4     18\n",
       "3     16\n",
       "8      7\n",
       "5      5\n",
       "Name: SibSp, dtype: int64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['SibSp'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parch's (Number of parents and children) relationship with survival is about as tenuous as Sibsp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parch\n",
       "0    0.343658\n",
       "1    0.550847\n",
       "2    0.500000\n",
       "3    0.600000\n",
       "4    0.000000\n",
       "5    0.200000\n",
       "6    0.000000\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Survived'].groupby(train['Parch']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    678\n",
       "1    118\n",
       "2     80\n",
       "5      5\n",
       "3      5\n",
       "4      4\n",
       "6      1\n",
       "Name: Parch, dtype: int64"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Parch'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parch and Sibsp seem less useful as of right now, but we'll return to these later and see what we can do with them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Ticket variable is not terribly useful on the surface, but given the high amount of null values for cabin, it may be possible to extrapolate to some degree where a passenger was given a room from their ticket number. For this initial overview, let's examine the amount of characters in the ticket and the beginning letter of the ticket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6     419\n",
       "5     131\n",
       "4     101\n",
       "8      76\n",
       "10     41\n",
       "7      27\n",
       "9      26\n",
       "17     14\n",
       "16     11\n",
       "13     10\n",
       "12     10\n",
       "15      9\n",
       "11      8\n",
       "18      6\n",
       "3       2\n",
       "Name: Ticket_Len, dtype: int64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Ticket_Len'] = train['Ticket'].apply(lambda x: len(x))\n",
    "train['Ticket_Len'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ticket_Len\n",
       "3     0.000000\n",
       "4     0.366337\n",
       "5     0.618321\n",
       "6     0.319809\n",
       "7     0.296296\n",
       "8     0.539474\n",
       "9     0.192308\n",
       "10    0.341463\n",
       "11    0.250000\n",
       "12    0.400000\n",
       "13    0.400000\n",
       "15    0.333333\n",
       "16    0.272727\n",
       "17    0.428571\n",
       "18    0.000000\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(['Ticket_Len'])['Survived'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    301\n",
       "2    183\n",
       "1    146\n",
       "P     65\n",
       "S     65\n",
       "C     47\n",
       "A     29\n",
       "W     13\n",
       "4     10\n",
       "7      9\n",
       "F      7\n",
       "6      6\n",
       "L      4\n",
       "5      3\n",
       "8      2\n",
       "9      1\n",
       "Name: Ticket_Lett, dtype: int64"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Ticket_Lett'] = train['Ticket'].apply(lambda x: str(x)[0])\n",
    "train['Ticket_Lett'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ticket_Lett\n",
       "1    0.630137\n",
       "2    0.464481\n",
       "3    0.239203\n",
       "4    0.200000\n",
       "5    0.000000\n",
       "6    0.166667\n",
       "7    0.111111\n",
       "8    0.000000\n",
       "9    1.000000\n",
       "A    0.068966\n",
       "C    0.340426\n",
       "F    0.571429\n",
       "L    0.250000\n",
       "P    0.646154\n",
       "S    0.323077\n",
       "W    0.153846\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(['Ticket_Lett'])['Survived'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fare should be rather similar to the results we find for Class when we compare them to our key survival metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.001, 8.662]    308\n",
       "(26.0, 512.329]    295\n",
       "(8.662, 26.0]      288\n",
       "Name: Fare, dtype: int64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.qcut(train['Fare'], 3).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fare\n",
       "(-0.001, 8.662]    0.198052\n",
       "(8.662, 26.0]      0.402778\n",
       "(26.0, 512.329]    0.559322\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Survived'].groupby(pd.qcut(train['Fare'], 3)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Pclass</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(-0.001, 8.662]</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(8.662, 26.0]</th>\n",
       "      <td>6</td>\n",
       "      <td>139</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(26.0, 512.329]</th>\n",
       "      <td>204</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Pclass             1    2    3\n",
       "Fare                          \n",
       "(-0.001, 8.662]    6    6  296\n",
       "(8.662, 26.0]      6  139  143\n",
       "(26.0, 512.329]  204   39   52"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(pd.qcut(train['Fare'], 3), columns=train['Pclass'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the Class and Fare variables are highly correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Cabin variable has by far the largest amount of null values, but let's see if we can't find a relationship between the exsiting Cabin numbers and the tickets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n    687\n",
       "C     59\n",
       "B     47\n",
       "D     33\n",
       "E     32\n",
       "A     15\n",
       "F     13\n",
       "G      4\n",
       "T      1\n",
       "Name: Cabin_Letter, dtype: int64"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Cabin_Letter'] = train['Cabin'].apply(lambda x: str(x)[0])\n",
    "train['Cabin_Letter'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cabin_Letter\n",
       "A    0.466667\n",
       "B    0.744681\n",
       "C    0.593220\n",
       "D    0.757576\n",
       "E    0.750000\n",
       "F    0.615385\n",
       "G    0.500000\n",
       "T    0.000000\n",
       "n    0.299854\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Survived'].groupby(train['Cabin_Letter']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['Cabin_num'] = train['Cabin'].apply(lambda x: str(x).split(' ')[-1][1:])\n",
    "train['Cabin_num'].replace('an', np.NaN, inplace = True)\n",
    "train['Cabin_num'] = train['Cabin_num'].apply(lambda x: int(x) if not pd.isnull(x) and x != '' else np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65.667, 148.0]     67\n",
       "(1.999, 28.667]     67\n",
       "(28.667, 65.667]    66\n",
       "Name: Cabin_num, dtype: int64"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.qcut(train['Cabin_num'],3).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cabin_num\n",
       "(1.999, 28.667]     0.716418\n",
       "(28.667, 65.667]    0.651515\n",
       "(65.667, 148.0]     0.641791\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Survived'].groupby(pd.qcut(train['Cabin_num'], 3)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.063845959227893712"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Survived'].corr(train['Cabin_num'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cabin number does not seem terribly indicative of survival, as indicated by the slightly less than zero correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Embarked variable shows that those who boarded at Cherbourg were more likely to survive, like because they were upper-class passengers. See attached link: https://www.encyclopedia-titanica.org/titanic-passengers-crew-embarked/2/cherbourg.html About half of the embarkees at Cherbourg were first class passengers, more than at any other port."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embarked\n",
       "C    0.553571\n",
       "Q    0.389610\n",
       "S    0.336957\n",
       "Name: Survived, dtype: float64"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Survived'].groupby(train['Embarked']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x231c6766a90>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x231c67064e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(train['Embarked'], hue=train['Pclass'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL PREP\n",
    "\n",
    "We first will want two columns: Passenger's name length, and passenger's title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def names(train, test):\n",
    "    for i in [train, test]:\n",
    "        i['Name_Len'] = i['Name'].apply(lambda x: len(x))\n",
    "        i['Name_Title'] = i['Name'].apply(lambda x: x.split(',')[1]).apply(lambda x: x.split()[0])\n",
    "        del i['Name']\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can fill in the null ages with the mean corresponding to the row's class and title. This allows for a more realistic approach than just filling the overall column's mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def age_impute(train, test):\n",
    "    for i in [train, test]:\n",
    "        i['Age_Null_Flag'] = i['Age'].apply(lambda x: 1 if pd.isnull(x) else 0)\n",
    "        data = train.groupby(['Name_Title', 'Pclass'])['Age']\n",
    "        i['Age'] = data.transform(lambda x: x.fillna(x.mean()))\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the Sibsp and Parch variables are rather weak indicators, let's combine them into a stronger one and create smaller buckets to put them in than just dummy variables for all combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fam_size(train, test):\n",
    "    for i in [train, test]:\n",
    "        i['Fam_Size'] = np.where((i['SibSp']+i['Parch']) == 0 , 'Solo',\n",
    "                           np.where((i['SibSp']+i['Parch']) <= 3,'Nuclear', 'Big'))\n",
    "        del i['SibSp']\n",
    "        del i['Parch']\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function allows us to split the Ticket column into ticket_lett and ticket_len, for reasons outlined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ticket_grouped(train, test):\n",
    "    for i in [train, test]:\n",
    "        i['Ticket_Lett'] = i['Ticket'].apply(lambda x: str(x)[0])\n",
    "        i['Ticket_Lett'] = i['Ticket_Lett'].apply(lambda x: str(x))\n",
    "        i['Ticket_Lett'] = np.where((i['Ticket_Lett']).isin(['1', '2', '3', 'S', 'P', 'C', 'A']), i['Ticket_Lett'],\n",
    "                                   np.where((i['Ticket_Lett']).isin(['W', '4', '7', '6', 'L', '5', '8']),\n",
    "                                            'Low_ticket', 'Other_ticket'))\n",
    "        i['Ticket_Len'] = i['Ticket'].apply(lambda x: len(x))\n",
    "        del i['Ticket']\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do the same thing with the Cabin variable, but for cabin letter and number:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cabin(train, test):\n",
    "    for i in [train, test]:\n",
    "        i['Cabin_Letter'] = i['Cabin'].apply(lambda x: str(x)[0])\n",
    "        del i['Cabin']\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cabin_num(train, test):\n",
    "    for i in [train, test]:\n",
    "        i['Cabin_num1'] = i['Cabin'].apply(lambda x: str(x).split(' ')[-1][1:])\n",
    "        i['Cabin_num1'].replace('an', np.NaN, inplace = True)\n",
    "        i['Cabin_num1'] = i['Cabin_num1'].apply(lambda x: int(x) if not pd.isnull(x) and x != '' else np.NaN)\n",
    "        i['Cabin_num'] = pd.qcut(train['Cabin_num1'],3)\n",
    "    train = pd.concat((train, pd.get_dummies(train['Cabin_num'], prefix = 'Cabin_num')), axis = 1)\n",
    "    test = pd.concat((test, pd.get_dummies(test['Cabin_num'], prefix = 'Cabin_num')), axis = 1)\n",
    "    del train['Cabin_num']\n",
    "    del test['Cabin_num']\n",
    "    del train['Cabin_num1']\n",
    "    del test['Cabin_num1']\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will resort to filling null values in Embarked with the most common port, Southampton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def embarked_impute(train, test):\n",
    "    for i in [train, test]:\n",
    "        i['Embarked'] = i['Embarked'].fillna('S')\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since one of the test set fares is missing, that will be filled with the mean of the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['Fare'].fillna(train['Fare'].mean(), inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dummy variables must now be created for all of our categorical columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dummies(train, test, columns = ['Pclass', 'Sex', 'Embarked', 'Ticket_Lett', 'Cabin_Letter', 'Name_Title', 'Fam_Size']):\n",
    "    for column in columns:\n",
    "        train[column] = train[column].apply(lambda x: str(x))\n",
    "        test[column] = test[column].apply(lambda x: str(x))\n",
    "        good_cols = [column+'_'+i for i in train[column].unique() if i in test[column].unique()]\n",
    "        train = pd.concat((train, pd.get_dummies(train[column], prefix = column)[good_cols]), axis = 1)\n",
    "        test = pd.concat((test, pd.get_dummies(test[column], prefix = column)[good_cols]), axis = 1)\n",
    "        del train[column]\n",
    "        del test[column]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For modelling purposes, we'll drop the Passenger ID variable, as it should have nothing to do with our prediction in the first place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def drop(train, test, bye = ['PassengerId']):\n",
    "    for i in [train, test]:\n",
    "        for z in bye:\n",
    "            del i[z]\n",
    "    return train, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join('C:\\\\Users\\\\michael.clawson\\\\Desktop\\School\\\\Machine Learning\\\\Titanic\\\\train.csv'))\n",
    "test = pd.read_csv(os.path.join('C:\\\\Users\\\\michael.clawson\\\\Desktop\\School\\\\Machine Learning\\\\Titanic\\\\test.csv'))\n",
    "train, test = names(train, test)\n",
    "train, test = age_impute(train, test)\n",
    "train, test = cabin_num(train, test)\n",
    "train, test = cabin(train, test)\n",
    "train, test = embarked_impute(train, test)\n",
    "train, test = fam_size(train, test)\n",
    "test['Fare'].fillna(train['Fare'].mean(), inplace = True)\n",
    "train, test = ticket_grouped(train, test)\n",
    "train, test = dummies(train, test, columns = ['Pclass', 'Sex', 'Embarked', 'Ticket_Lett',\n",
    "                                                                     'Cabin_Letter', 'Name_Title', 'Fam_Size'])\n",
    "train, test = drop(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "print(len(train.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a 44-variable model, with all nulls imputed and all dummies separated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data prepped and ready to go, let's search correct hyper parameters for a random forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.838383838384\n",
      "{'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 700}\n",
      "{'mean_fit_time': array([ 0.25167918,  0.57233151,  1.97179977,  2.88771025,  5.52701807,\n",
      "        0.48067427,  0.6514682 ,  1.91481773,  3.79853272,  6.23159226,\n",
      "        0.59692351,  0.73168604,  2.05879418,  3.13455963,  4.68415634,\n",
      "        0.25217851,  0.67431196,  1.93187253,  2.81750512,  4.25201829,\n",
      "        0.24367277,  0.73885886,  1.74840673,  2.93424924,  4.65573144,\n",
      "        0.39227843,  0.52755054,  1.6625127 ,  2.76295988,  4.09807412,\n",
      "        0.23883637,  0.59208711,  1.68302735,  3.00213003,  4.16795746,\n",
      "        0.24467413,  0.61226781,  1.60447359,  2.81017113,  4.28404363,\n",
      "        0.23833593,  0.51753394,  1.93203823,  2.9519275 ,  4.25221205,\n",
      "        0.25268118,  0.75304834,  1.71037992,  2.75712268,  4.18597039,\n",
      "        0.27202638,  0.44181315,  2.16286755,  2.60267981,  3.96281163,\n",
      "        0.23983622,  0.40361945,  1.86425702,  2.78447652,  4.34641719,\n",
      "        0.26101804,  0.61593731,  1.97356653,  2.79314868,  5.01439095,\n",
      "        0.25518211,  0.76254129,  2.08514643,  3.41892449,  4.46066515,\n",
      "        0.23716847,  0.65963475,  1.78710175,  2.87370571,  4.1959823 ,\n",
      "        0.25985074,  0.53087703,  2.40237077,  3.01297116,  4.52888052,\n",
      "        0.24967686,  0.48300942,  2.17821193,  3.0613389 ,  4.70267002,\n",
      "        0.3941129 ,  0.68014956,  1.67535504,  2.94893209,  4.66798917,\n",
      "        0.24417313,  0.71200983,  2.13851674,  3.32369129,  4.47117225,\n",
      "        0.22382474,  0.58758378,  1.79243835,  2.92624323,  4.41746759,\n",
      "        0.24850965,  0.55856307,  2.04828668,  3.06934388,  4.47601636,\n",
      "        0.25951719,  0.52670741,  1.8189706 ,  2.58500012,  3.86507559,\n",
      "        0.30688365,  0.61877211,  1.42050767,  2.36796943,  3.61239759,\n",
      "        0.21806232,  0.39677755,  1.64214436,  2.35359581,  3.73269312,\n",
      "        0.25867271,  0.5353864 ,  1.45206634,  2.33230829,  3.4850297 ,\n",
      "        0.22072164,  0.5580914 ,  1.45070752,  2.30935558,  3.60278106,\n",
      "        0.21962468,  0.55602813,  1.57009125,  2.3422699 ,  3.53421394,\n",
      "        0.21545521,  0.42263103,  1.36703626,  2.26658098,  3.39840865,\n",
      "        0.21497337,  0.55712374,  1.5797925 ,  2.32411202,  3.34625435,\n",
      "        0.220191  ,  0.45864868,  1.44461584,  2.31943957,  3.01436814]), 'std_fit_time': array([ 0.04700605,  0.01987966,  0.29178339,  0.17478464,  0.54990981,\n",
      "        0.08019369,  0.08484959,  0.12900008,  0.09032851,  0.35231828,\n",
      "        0.08171995,  0.16896392,  0.24671815,  0.03463181,  0.14621823,\n",
      "        0.0230054 ,  0.08508608,  0.09644656,  0.1122681 ,  0.23893245,\n",
      "        0.02433829,  0.2885974 ,  0.06180178,  0.12799296,  0.09406059,\n",
      "        0.08976641,  0.07298635,  0.1053882 ,  0.1211176 ,  0.06066848,\n",
      "        0.01908543,  0.15068839,  0.08604703,  0.17357649,  0.33209782,\n",
      "        0.01859195,  0.15801579,  0.05621824,  0.03969337,  0.19100943,\n",
      "        0.01608575,  0.11017784,  0.02323415,  0.18716239,  0.10228766,\n",
      "        0.03529117,  0.28317283,  0.07065736,  0.10538731,  0.26813834,\n",
      "        0.05179005,  0.02857115,  0.13522562,  0.11808265,  0.06980651,\n",
      "        0.00866082,  0.09299041,  0.26328667,  0.15001392,  0.1258743 ,\n",
      "        0.03217904,  0.08224415,  0.0656926 ,  0.09647082,  0.39711529,\n",
      "        0.00966047,  0.11575709,  0.0529116 ,  0.37985223,  0.47913556,\n",
      "        0.0231503 ,  0.30003091,  0.04086498,  0.06336197,  0.14971986,\n",
      "        0.00908342,  0.16398323,  0.14788657,  0.07568597,  0.13323606,\n",
      "        0.02249947,  0.09346885,  0.30415987,  0.09304553,  0.04460671,\n",
      "        0.11008242,  0.26872922,  0.05064163,  0.14299162,  0.25849725,\n",
      "        0.01773289,  0.04780019,  0.01284191,  0.15024899,  0.14523968,\n",
      "        0.01631277,  0.06250851,  0.02679678,  0.10112952,  0.17716308,\n",
      "        0.02597097,  0.14184538,  0.05383121,  0.02964748,  0.16059184,\n",
      "        0.02657151,  0.05564572,  0.0570491 ,  0.03379876,  0.03125893,\n",
      "        0.07482525,  0.20472202,  0.13168592,  0.11088609,  0.10091041,\n",
      "        0.01852129,  0.06156687,  0.06688731,  0.06251765,  0.13998853,\n",
      "        0.06201657,  0.07333488,  0.02553144,  0.04797561,  0.15933748,\n",
      "        0.02019465,  0.13623453,  0.07343185,  0.07785338,  0.14898361,\n",
      "        0.00881132,  0.1485062 ,  0.06120441,  0.03773585,  0.10030005,\n",
      "        0.0092798 ,  0.01233216,  0.09331894,  0.01855199,  0.07543668,\n",
      "        0.01304619,  0.11300432,  0.06946769,  0.1988982 ,  0.06410648,\n",
      "        0.01399547,  0.07587886,  0.02474351,  0.05710583,  0.37281807]), 'mean_score_time': array([ 0.10622724,  0.11336112,  0.21548661,  0.29720235,  0.43069188,\n",
      "        0.33240207,  0.12207747,  0.19101493,  0.72918383,  0.46032691,\n",
      "        0.31689374,  0.18980098,  0.18613195,  0.28069711,  0.44948634,\n",
      "        0.10857741,  0.23950322,  0.21648685,  0.31839283,  0.3162233 ,\n",
      "        0.13176004,  0.10990898,  0.21898921,  0.38852326,  0.39245288,\n",
      "        0.13292789,  0.10891008,  0.21581976,  0.2168208 ,  0.37826912,\n",
      "        0.1120793 ,  0.1094106 ,  0.21982233,  0.35225034,  0.36058903,\n",
      "        0.11341333,  0.12258712,  0.15861281,  0.28903834,  0.33490467,\n",
      "        0.1064086 ,  0.11007818,  0.24017072,  0.21548653,  0.32806603,\n",
      "        0.10590553,  0.13911335,  0.21531963,  0.256682  ,  0.41813016,\n",
      "        0.10590847,  0.14126738,  0.25784985,  0.28720411,  0.32056117,\n",
      "        0.1159157 ,  0.11074559,  0.21948926,  0.25751623,  0.43630926,\n",
      "        0.19947473,  0.12975828,  0.18079519,  0.3018806 ,  0.46716436,\n",
      "        0.11491394,  0.15544311,  0.19413845,  0.32439621,  0.36659368,\n",
      "        0.1085767 ,  0.13526217,  0.22666025,  0.28403497,  0.4846824 ,\n",
      "        0.10874391,  0.11475205,  0.28820443,  0.28403497,  0.36092257,\n",
      "        0.1242547 ,  0.11041133,  0.20864765,  0.2511785 ,  0.35758678,\n",
      "        0.2703588 ,  0.14293504,  0.21481983,  0.29187417,  0.38594103,\n",
      "        0.11508187,  0.1370976 ,  0.29437582,  0.2646877 ,  0.35958878,\n",
      "        0.10674254,  0.12342072,  0.19263641,  0.32806595,  0.36375793,\n",
      "        0.10774302,  0.18463103,  0.22115644,  0.29137381,  0.34874741,\n",
      "        0.12425542,  0.11458166,  0.21215034,  0.24500751,  0.3193934 ,\n",
      "        0.21331835,  0.12608933,  0.20881494,  0.21857691,  0.33721908,\n",
      "        0.10692954,  0.10996024,  0.17717743,  0.21193131,  0.33903329,\n",
      "        0.18281507,  0.13683033,  0.17794053,  0.23483332,  0.31570156,\n",
      "        0.10890412,  0.10888592,  0.17563295,  0.21064957,  0.39834468,\n",
      "        0.11859393,  0.14550408,  0.21264919,  0.22001036,  0.31973958,\n",
      "        0.10526975,  0.10788631,  0.14261103,  0.21076695,  0.32770936,\n",
      "        0.10771314,  0.11881479,  0.17763702,  0.21029973,  0.31415224,\n",
      "        0.10764003,  0.10650444,  0.14225586,  0.24994493,  0.31774982]), 'std_score_time': array([ 0.00184365,  0.00188599,  0.06961189,  0.061221  ,  0.06519025,\n",
      "        0.17974151,  0.01240648,  0.0566915 ,  0.06783764,  0.03680479,\n",
      "        0.20035806,  0.08141517,  0.04658607,  0.08113218,  0.10289649,\n",
      "        0.00531077,  0.03459423,  0.00719693,  0.00379575,  0.00642093,\n",
      "        0.03150121,  0.00366295,  0.00411308,  0.16266457,  0.04826097,\n",
      "        0.03306145,  0.00131342,  0.00417268,  0.00960136,  0.06151468,\n",
      "        0.00567478,  0.00614688,  0.0055468 ,  0.10305927,  0.05719947,\n",
      "        0.0110858 ,  0.0227021 ,  0.04210724,  0.05483733,  0.01262092,\n",
      "        0.00094342,  0.00511859,  0.02147494,  0.00847505,  0.00259478,\n",
      "        0.0002399 ,  0.02307199,  0.00396776,  0.04396475,  0.07603029,\n",
      "        0.00023608,  0.04318618,  0.07241682,  0.05118299,  0.00154683,\n",
      "        0.0100763 ,  0.00436847,  0.00478756,  0.04375813,  0.02715113,\n",
      "        0.06690833,  0.02890092,  0.05291243,  0.05628379,  0.05206624,\n",
      "        0.00685059,  0.04237845,  0.04514031,  0.0430042 ,  0.05722662,\n",
      "        0.00324304,  0.02524134,  0.00285923,  0.04872792,  0.17188554,\n",
      "        0.00278145,  0.01025169,  0.10545384,  0.05580104,  0.05297194,\n",
      "        0.01700873,  0.00165145,  0.00216197,  0.05848094,  0.06770522,\n",
      "        0.14103132,  0.05035899,  0.00449966,  0.05065931,  0.0586734 ,\n",
      "        0.01106067,  0.01310514,  0.08907993,  0.07111473,  0.0543055 ,\n",
      "        0.00094381,  0.01598162,  0.04150831,  0.01363759,  0.02385983,\n",
      "        0.00246245,  0.06316789,  0.01405173,  0.04882379,  0.04940279,\n",
      "        0.01331592,  0.00147323,  0.00216182,  0.04618927,  0.00833564,\n",
      "        0.08028797,  0.02867652,  0.00249615,  0.00349691,  0.01520159,\n",
      "        0.00167568,  0.00606279,  0.04857669,  0.00121378,  0.02000737,\n",
      "        0.05883771,  0.04087677,  0.05243968,  0.01626162,  0.00362019,\n",
      "        0.00118416,  0.00207269,  0.04883263,  0.00285976,  0.09204734,\n",
      "        0.01550939,  0.02623679,  0.00267908,  0.00700158,  0.00952079,\n",
      "        0.00198542,  0.00313073,  0.04463406,  0.00191809,  0.01128155,\n",
      "        0.00054759,  0.01442699,  0.04673847,  0.00466033,  0.00117323,\n",
      "        0.00075682,  0.00122356,  0.04871546,  0.0543132 ,  0.00566013]), 'param_criterion': masked_array(data = ['gini' 'gini' 'gini' 'gini' 'gini' 'gini' 'gini' 'gini' 'gini' 'gini'\n",
      " 'gini' 'gini' 'gini' 'gini' 'gini' 'gini' 'gini' 'gini' 'gini' 'gini'\n",
      " 'gini' 'gini' 'gini' 'gini' 'gini' 'gini' 'gini' 'gini' 'gini' 'gini'\n",
      " 'gini' 'gini' 'gini' 'gini' 'gini' 'gini' 'gini' 'gini' 'gini' 'gini'\n",
      " 'gini' 'gini' 'gini' 'gini' 'gini' 'gini' 'gini' 'gini' 'gini' 'gini'\n",
      " 'gini' 'gini' 'gini' 'gini' 'gini' 'gini' 'gini' 'gini' 'gini' 'gini'\n",
      " 'gini' 'gini' 'gini' 'gini' 'gini' 'gini' 'gini' 'gini' 'gini' 'gini'\n",
      " 'gini' 'gini' 'gini' 'gini' 'gini' 'entropy' 'entropy' 'entropy' 'entropy'\n",
      " 'entropy' 'entropy' 'entropy' 'entropy' 'entropy' 'entropy' 'entropy'\n",
      " 'entropy' 'entropy' 'entropy' 'entropy' 'entropy' 'entropy' 'entropy'\n",
      " 'entropy' 'entropy' 'entropy' 'entropy' 'entropy' 'entropy' 'entropy'\n",
      " 'entropy' 'entropy' 'entropy' 'entropy' 'entropy' 'entropy' 'entropy'\n",
      " 'entropy' 'entropy' 'entropy' 'entropy' 'entropy' 'entropy' 'entropy'\n",
      " 'entropy' 'entropy' 'entropy' 'entropy' 'entropy' 'entropy' 'entropy'\n",
      " 'entropy' 'entropy' 'entropy' 'entropy' 'entropy' 'entropy' 'entropy'\n",
      " 'entropy' 'entropy' 'entropy' 'entropy' 'entropy' 'entropy' 'entropy'\n",
      " 'entropy' 'entropy' 'entropy' 'entropy' 'entropy' 'entropy' 'entropy'\n",
      " 'entropy' 'entropy' 'entropy' 'entropy' 'entropy' 'entropy' 'entropy'\n",
      " 'entropy'],\n",
      "             mask = [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False],\n",
      "       fill_value = ?)\n",
      ", 'param_min_samples_leaf': masked_array(data = [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 5 5 5 5 5 5 5 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5 5 5 5 5 5 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 10 10 10 10 10 10 10\n",
      " 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10 10],\n",
      "             mask = [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False],\n",
      "       fill_value = ?)\n",
      ", 'param_min_samples_split': masked_array(data = [2 2 2 2 2 4 4 4 4 4 10 10 10 10 10 12 12 12 12 12 16 16 16 16 16 2 2 2 2 2\n",
      " 4 4 4 4 4 10 10 10 10 10 12 12 12 12 12 16 16 16 16 16 2 2 2 2 2 4 4 4 4 4\n",
      " 10 10 10 10 10 12 12 12 12 12 16 16 16 16 16 2 2 2 2 2 4 4 4 4 4 10 10 10\n",
      " 10 10 12 12 12 12 12 16 16 16 16 16 2 2 2 2 2 4 4 4 4 4 10 10 10 10 10 12\n",
      " 12 12 12 12 16 16 16 16 16 2 2 2 2 2 4 4 4 4 4 10 10 10 10 10 12 12 12 12\n",
      " 12 16 16 16 16 16],\n",
      "             mask = [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False],\n",
      "       fill_value = ?)\n",
      ", 'param_n_estimators': masked_array(data = [50 100 400 700 1000 50 100 400 700 1000 50 100 400 700 1000 50 100 400 700\n",
      " 1000 50 100 400 700 1000 50 100 400 700 1000 50 100 400 700 1000 50 100\n",
      " 400 700 1000 50 100 400 700 1000 50 100 400 700 1000 50 100 400 700 1000\n",
      " 50 100 400 700 1000 50 100 400 700 1000 50 100 400 700 1000 50 100 400 700\n",
      " 1000 50 100 400 700 1000 50 100 400 700 1000 50 100 400 700 1000 50 100\n",
      " 400 700 1000 50 100 400 700 1000 50 100 400 700 1000 50 100 400 700 1000\n",
      " 50 100 400 700 1000 50 100 400 700 1000 50 100 400 700 1000 50 100 400 700\n",
      " 1000 50 100 400 700 1000 50 100 400 700 1000 50 100 400 700 1000 50 100\n",
      " 400 700 1000],\n",
      "             mask = [False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False False],\n",
      "       fill_value = ?)\n",
      ", 'params': [{'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 1000}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 50}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 100}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 400}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 700}, {'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 4, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 12, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 1, 'min_samples_split': 16, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 4, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 10, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 12, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 5, 'min_samples_split': 16, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 2, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 4, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 10, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 12, 'n_estimators': 1000}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 50}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 100}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 400}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 700}, {'criterion': 'entropy', 'min_samples_leaf': 10, 'min_samples_split': 16, 'n_estimators': 1000}], 'split0_test_score': array([ 0.80808081,  0.8013468 ,  0.80808081,  0.81481481,  0.8047138 ,\n",
      "        0.81818182,  0.83164983,  0.82491582,  0.82491582,  0.82491582,\n",
      "        0.81144781,  0.81144781,  0.80808081,  0.81481481,  0.81818182,\n",
      "        0.80808081,  0.80808081,  0.81144781,  0.8047138 ,  0.80808081,\n",
      "        0.81481481,  0.80808081,  0.80808081,  0.80808081,  0.80808081,\n",
      "        0.82154882,  0.81818182,  0.81818182,  0.81818182,  0.81818182,\n",
      "        0.82154882,  0.81818182,  0.81818182,  0.81818182,  0.81818182,\n",
      "        0.82154882,  0.81818182,  0.81818182,  0.81818182,  0.81818182,\n",
      "        0.83164983,  0.82491582,  0.81818182,  0.81818182,  0.81818182,\n",
      "        0.83164983,  0.82828283,  0.81481481,  0.81818182,  0.82154882,\n",
      "        0.81818182,  0.82154882,  0.81144781,  0.81481481,  0.81144781,\n",
      "        0.81818182,  0.82154882,  0.81144781,  0.81481481,  0.81144781,\n",
      "        0.81818182,  0.82154882,  0.81144781,  0.81481481,  0.81144781,\n",
      "        0.81818182,  0.82154882,  0.81144781,  0.81481481,  0.81144781,\n",
      "        0.81818182,  0.82154882,  0.81144781,  0.81481481,  0.81144781,\n",
      "        0.8013468 ,  0.80808081,  0.81144781,  0.81144781,  0.80808081,\n",
      "        0.81144781,  0.80808081,  0.82491582,  0.82491582,  0.82491582,\n",
      "        0.80808081,  0.80808081,  0.81144781,  0.81144781,  0.81144781,\n",
      "        0.82828283,  0.81481481,  0.81144781,  0.81481481,  0.81481481,\n",
      "        0.80808081,  0.80808081,  0.81481481,  0.81481481,  0.81144781,\n",
      "        0.80808081,  0.81144781,  0.80808081,  0.81144781,  0.81481481,\n",
      "        0.80808081,  0.81144781,  0.80808081,  0.81144781,  0.81481481,\n",
      "        0.80808081,  0.81144781,  0.80808081,  0.81144781,  0.81481481,\n",
      "        0.81818182,  0.80808081,  0.81144781,  0.81144781,  0.81818182,\n",
      "        0.8047138 ,  0.81144781,  0.81144781,  0.81144781,  0.81481481,\n",
      "        0.82828283,  0.82154882,  0.80808081,  0.80808081,  0.80808081,\n",
      "        0.82828283,  0.82154882,  0.80808081,  0.80808081,  0.80808081,\n",
      "        0.82828283,  0.82154882,  0.80808081,  0.80808081,  0.80808081,\n",
      "        0.82828283,  0.82154882,  0.80808081,  0.80808081,  0.80808081,\n",
      "        0.82828283,  0.82154882,  0.80808081,  0.80808081,  0.80808081]), 'split1_test_score': array([ 0.84511785,  0.85185185,  0.85858586,  0.85521886,  0.85521886,\n",
      "        0.84848485,  0.84175084,  0.85185185,  0.85185185,  0.84848485,\n",
      "        0.85185185,  0.84848485,  0.85521886,  0.85858586,  0.85858586,\n",
      "        0.83164983,  0.83838384,  0.84511785,  0.85185185,  0.85185185,\n",
      "        0.85858586,  0.84511785,  0.83838384,  0.84848485,  0.84511785,\n",
      "        0.82828283,  0.82828283,  0.83838384,  0.83838384,  0.83501684,\n",
      "        0.82828283,  0.82828283,  0.83838384,  0.83838384,  0.83501684,\n",
      "        0.82828283,  0.82828283,  0.83838384,  0.83838384,  0.83501684,\n",
      "        0.83164983,  0.83838384,  0.83164983,  0.84175084,  0.83501684,\n",
      "        0.82828283,  0.83164983,  0.83501684,  0.83501684,  0.83838384,\n",
      "        0.81818182,  0.83501684,  0.83164983,  0.83164983,  0.83164983,\n",
      "        0.81818182,  0.83501684,  0.83164983,  0.83164983,  0.83164983,\n",
      "        0.81818182,  0.83501684,  0.83164983,  0.83164983,  0.83164983,\n",
      "        0.81818182,  0.83501684,  0.83164983,  0.83164983,  0.83164983,\n",
      "        0.81818182,  0.83501684,  0.83164983,  0.83164983,  0.83164983,\n",
      "        0.83838384,  0.84511785,  0.85858586,  0.86195286,  0.86195286,\n",
      "        0.84511785,  0.86195286,  0.84848485,  0.84848485,  0.84848485,\n",
      "        0.84175084,  0.84175084,  0.84511785,  0.84848485,  0.84848485,\n",
      "        0.85185185,  0.85521886,  0.84848485,  0.84848485,  0.85521886,\n",
      "        0.84511785,  0.84848485,  0.84511785,  0.85185185,  0.84511785,\n",
      "        0.83501684,  0.84511785,  0.83501684,  0.83164983,  0.83501684,\n",
      "        0.83501684,  0.84511785,  0.83501684,  0.83164983,  0.83501684,\n",
      "        0.83501684,  0.84511785,  0.83501684,  0.83164983,  0.83501684,\n",
      "        0.82828283,  0.84848485,  0.83838384,  0.83501684,  0.83501684,\n",
      "        0.83501684,  0.84511785,  0.83164983,  0.83838384,  0.83838384,\n",
      "        0.83164983,  0.83164983,  0.83501684,  0.83164983,  0.82828283,\n",
      "        0.83164983,  0.83164983,  0.83501684,  0.83164983,  0.82828283,\n",
      "        0.83164983,  0.83164983,  0.83501684,  0.83164983,  0.82828283,\n",
      "        0.83164983,  0.83164983,  0.83501684,  0.83164983,  0.82828283,\n",
      "        0.83164983,  0.83164983,  0.83501684,  0.83164983,  0.82828283]), 'split2_test_score': array([ 0.82491582,  0.82828283,  0.83164983,  0.82828283,  0.82491582,\n",
      "        0.84511785,  0.83838384,  0.83164983,  0.83501684,  0.83501684,\n",
      "        0.84175084,  0.84511785,  0.83838384,  0.84175084,  0.83838384,\n",
      "        0.84175084,  0.84511785,  0.84175084,  0.84175084,  0.84175084,\n",
      "        0.82828283,  0.84511785,  0.83838384,  0.83501684,  0.83838384,\n",
      "        0.82154882,  0.82828283,  0.81481481,  0.81481481,  0.82154882,\n",
      "        0.82154882,  0.82828283,  0.81481481,  0.81481481,  0.82154882,\n",
      "        0.82154882,  0.82828283,  0.81481481,  0.81481481,  0.82154882,\n",
      "        0.81818182,  0.81818182,  0.81481481,  0.81481481,  0.81481481,\n",
      "        0.81144781,  0.80808081,  0.81818182,  0.81481481,  0.81818182,\n",
      "        0.82491582,  0.80808081,  0.7979798 ,  0.7979798 ,  0.7979798 ,\n",
      "        0.82491582,  0.80808081,  0.7979798 ,  0.7979798 ,  0.7979798 ,\n",
      "        0.82491582,  0.80808081,  0.7979798 ,  0.7979798 ,  0.7979798 ,\n",
      "        0.82491582,  0.80808081,  0.7979798 ,  0.7979798 ,  0.7979798 ,\n",
      "        0.82491582,  0.80808081,  0.7979798 ,  0.7979798 ,  0.7979798 ,\n",
      "        0.83838384,  0.82828283,  0.82828283,  0.82491582,  0.82154882,\n",
      "        0.82828283,  0.83838384,  0.84175084,  0.83501684,  0.83164983,\n",
      "        0.83838384,  0.84511785,  0.83501684,  0.84511785,  0.83838384,\n",
      "        0.83501684,  0.83501684,  0.84175084,  0.84175084,  0.84175084,\n",
      "        0.84175084,  0.85185185,  0.84175084,  0.83838384,  0.83838384,\n",
      "        0.81818182,  0.81818182,  0.81144781,  0.81481481,  0.81818182,\n",
      "        0.81818182,  0.81818182,  0.81144781,  0.81481481,  0.81818182,\n",
      "        0.81818182,  0.81818182,  0.81144781,  0.81481481,  0.81818182,\n",
      "        0.82154882,  0.82491582,  0.82154882,  0.82491582,  0.82491582,\n",
      "        0.83164983,  0.82154882,  0.82828283,  0.82154882,  0.82154882,\n",
      "        0.81818182,  0.8013468 ,  0.7979798 ,  0.7979798 ,  0.7979798 ,\n",
      "        0.81818182,  0.8013468 ,  0.7979798 ,  0.7979798 ,  0.7979798 ,\n",
      "        0.81818182,  0.8013468 ,  0.7979798 ,  0.7979798 ,  0.7979798 ,\n",
      "        0.81818182,  0.8013468 ,  0.7979798 ,  0.7979798 ,  0.7979798 ,\n",
      "        0.81818182,  0.8013468 ,  0.7979798 ,  0.7979798 ,  0.7979798 ]), 'mean_test_score': array([ 0.82603816,  0.82716049,  0.83277217,  0.83277217,  0.82828283,\n",
      "        0.8372615 ,  0.8372615 ,  0.83613917,  0.8372615 ,  0.83613917,\n",
      "        0.83501684,  0.83501684,  0.8338945 ,  0.83838384,  0.83838384,\n",
      "        0.82716049,  0.8305275 ,  0.83277217,  0.83277217,  0.8338945 ,\n",
      "        0.8338945 ,  0.83277217,  0.82828283,  0.8305275 ,  0.8305275 ,\n",
      "        0.82379349,  0.82491582,  0.82379349,  0.82379349,  0.82491582,\n",
      "        0.82379349,  0.82491582,  0.82379349,  0.82379349,  0.82491582,\n",
      "        0.82379349,  0.82491582,  0.82379349,  0.82379349,  0.82491582,\n",
      "        0.82716049,  0.82716049,  0.82154882,  0.82491582,  0.82267116,\n",
      "        0.82379349,  0.82267116,  0.82267116,  0.82267116,  0.82603816,\n",
      "        0.82042649,  0.82154882,  0.81369248,  0.81481481,  0.81369248,\n",
      "        0.82042649,  0.82154882,  0.81369248,  0.81481481,  0.81369248,\n",
      "        0.82042649,  0.82154882,  0.81369248,  0.81481481,  0.81369248,\n",
      "        0.82042649,  0.82154882,  0.81369248,  0.81481481,  0.81369248,\n",
      "        0.82042649,  0.82154882,  0.81369248,  0.81481481,  0.81369248,\n",
      "        0.82603816,  0.82716049,  0.83277217,  0.83277217,  0.8305275 ,\n",
      "        0.82828283,  0.83613917,  0.83838384,  0.83613917,  0.83501684,\n",
      "        0.82940516,  0.83164983,  0.8305275 ,  0.83501684,  0.83277217,\n",
      "        0.83838384,  0.83501684,  0.8338945 ,  0.83501684,  0.8372615 ,\n",
      "        0.83164983,  0.83613917,  0.8338945 ,  0.83501684,  0.83164983,\n",
      "        0.82042649,  0.82491582,  0.81818182,  0.81930415,  0.82267116,\n",
      "        0.82042649,  0.82491582,  0.81818182,  0.81930415,  0.82267116,\n",
      "        0.82042649,  0.82491582,  0.81818182,  0.81930415,  0.82267116,\n",
      "        0.82267116,  0.82716049,  0.82379349,  0.82379349,  0.82603816,\n",
      "        0.82379349,  0.82603816,  0.82379349,  0.82379349,  0.82491582,\n",
      "        0.82603816,  0.81818182,  0.81369248,  0.81257015,  0.81144781,\n",
      "        0.82603816,  0.81818182,  0.81369248,  0.81257015,  0.81144781,\n",
      "        0.82603816,  0.81818182,  0.81369248,  0.81257015,  0.81144781,\n",
      "        0.82603816,  0.81818182,  0.81369248,  0.81257015,  0.81144781,\n",
      "        0.82603816,  0.81818182,  0.81369248,  0.81257015,  0.81144781]), 'std_test_score': array([ 0.01514112,  0.02063387,  0.02063387,  0.01679756,  0.0207556 ,\n",
      "        0.01356122,  0.00419939,  0.01144561,  0.01111054,  0.00965469,\n",
      "        0.01716842,  0.01672241,  0.01950409,  0.01802736,  0.01649488,\n",
      "        0.01410753,  0.01610853,  0.01514112,  0.02026428,  0.01871305,\n",
      "        0.01830472,  0.01745943,  0.01428499,  0.01679756,  0.01610853,\n",
      "        0.00317444,  0.00476166,  0.0104081 ,  0.0104081 ,  0.00727356,\n",
      "        0.00317444,  0.00476166,  0.0104081 ,  0.0104081 ,  0.00727356,\n",
      "        0.00317444,  0.00476166,  0.0104081 ,  0.0104081 ,  0.00727356,\n",
      "        0.00634888,  0.00839878,  0.00727356,  0.01198325,  0.00883727,\n",
      "        0.00883727,  0.0104081 ,  0.00883727,  0.00883727,  0.00883727,\n",
      "        0.00317444,  0.01099659,  0.01383707,  0.01374573,  0.01383707,\n",
      "        0.00317444,  0.01099659,  0.01383707,  0.01374573,  0.01383707,\n",
      "        0.00317444,  0.01099659,  0.01383707,  0.01374573,  0.01383707,\n",
      "        0.00317444,  0.01099659,  0.01383707,  0.01374573,  0.01383707,\n",
      "        0.00317444,  0.01099659,  0.01383707,  0.01374573,  0.01383707,\n",
      "        0.01745943,  0.01514112,  0.01950409,  0.02135387,  0.02289122,\n",
      "        0.01374573,  0.02205037,  0.00991219,  0.00965469,  0.00991219,\n",
      "        0.01514112,  0.01672241,  0.01410753,  0.01672241,  0.01563231,\n",
      "        0.00991219,  0.01649488,  0.01610853,  0.01454712,  0.01679756,\n",
      "        0.01672241,  0.01988782,  0.01356122,  0.0153066 ,  0.01454712,\n",
      "        0.01111054,  0.01454712,  0.01198325,  0.00883727,  0.00883727,\n",
      "        0.01111054,  0.01454712,  0.01198325,  0.00883727,  0.00883727,\n",
      "        0.01111054,  0.01454712,  0.01198325,  0.00883727,  0.00883727,\n",
      "        0.00419939,  0.01657107,  0.01111054,  0.00965469,  0.00691853,\n",
      "        0.01356122,  0.01410753,  0.00883727,  0.01111054,  0.00991219,\n",
      "        0.00572281,  0.01259817,  0.01563231,  0.01410753,  0.01259817,\n",
      "        0.00572281,  0.01259817,  0.01563231,  0.01410753,  0.01259817,\n",
      "        0.00572281,  0.01259817,  0.01563231,  0.01410753,  0.01259817,\n",
      "        0.00572281,  0.01259817,  0.01563231,  0.01410753,  0.01259817,\n",
      "        0.00572281,  0.01259817,  0.01563231,  0.01410753,  0.01259817]), 'rank_test_score': array([ 52,  46,  26,  26,  43,   5,   5,   9,   5,   9,  14,  14,  21,\n",
      "         1,   1,  46,  37,  26,  26,  21,  21,  26,  43,  37,  37,  73,\n",
      "        62,  73,  73,  62,  73,  62,  73,  73,  62,  73,  62,  73,  73,\n",
      "        62,  46,  46,  96,  62,  88,  73,  88,  88,  88,  52, 102,  96,\n",
      "       126, 121, 126, 102,  96, 126, 121, 126, 102,  96, 126, 121, 126,\n",
      "       102,  96, 126, 121, 126, 102,  96, 126, 121, 126,  52,  46,  26,\n",
      "        26,  37,  43,   9,   1,   9,  14,  42,  34,  37,  14,  26,   1,\n",
      "        14,  21,  14,   5,  34,   9,  21,  14,  34, 102,  62, 113, 110,\n",
      "        88, 102,  62, 113, 110,  88, 102,  62, 113, 110,  88,  88,  46,\n",
      "        73,  73,  52,  73,  52,  73,  73,  62,  52, 113, 126, 141, 146,\n",
      "        52, 113, 126, 141, 146,  52, 113, 126, 141, 146,  52, 113, 126,\n",
      "       141, 146,  52, 113, 126, 141, 146]), 'split0_train_score': array([ 0.9983165 ,  0.9983165 ,  0.9983165 ,  0.9983165 ,  0.9983165 ,\n",
      "        0.96969697,  0.97138047,  0.96969697,  0.96969697,  0.97138047,\n",
      "        0.91750842,  0.92424242,  0.92592593,  0.92424242,  0.92929293,\n",
      "        0.91077441,  0.91414141,  0.91582492,  0.91245791,  0.91245791,\n",
      "        0.90740741,  0.90909091,  0.90909091,  0.90740741,  0.90740741,\n",
      "        0.88383838,  0.88383838,  0.88383838,  0.88888889,  0.88720539,\n",
      "        0.88383838,  0.88383838,  0.88383838,  0.88888889,  0.88720539,\n",
      "        0.88383838,  0.88383838,  0.88383838,  0.88888889,  0.88720539,\n",
      "        0.88215488,  0.88047138,  0.88552189,  0.88552189,  0.88720539,\n",
      "        0.87373737,  0.88047138,  0.88047138,  0.88383838,  0.88215488,\n",
      "        0.85521886,  0.85858586,  0.87878788,  0.87710438,  0.87542088,\n",
      "        0.85521886,  0.85858586,  0.87878788,  0.87710438,  0.87542088,\n",
      "        0.85521886,  0.85858586,  0.87878788,  0.87710438,  0.87542088,\n",
      "        0.85521886,  0.85858586,  0.87878788,  0.87710438,  0.87542088,\n",
      "        0.85521886,  0.85858586,  0.87878788,  0.87710438,  0.87542088,\n",
      "        0.9983165 ,  0.9983165 ,  0.9983165 ,  0.9983165 ,  0.9983165 ,\n",
      "        0.96969697,  0.97138047,  0.97306397,  0.97306397,  0.97138047,\n",
      "        0.91750842,  0.92424242,  0.92760943,  0.93097643,  0.92929293,\n",
      "        0.90572391,  0.91245791,  0.91750842,  0.91919192,  0.92087542,\n",
      "        0.9040404 ,  0.9040404 ,  0.90740741,  0.90909091,  0.90740741,\n",
      "        0.88215488,  0.88888889,  0.88720539,  0.88552189,  0.88552189,\n",
      "        0.88215488,  0.88888889,  0.88720539,  0.88552189,  0.88552189,\n",
      "        0.88215488,  0.88888889,  0.88720539,  0.88552189,  0.88552189,\n",
      "        0.88215488,  0.88552189,  0.88383838,  0.88552189,  0.88383838,\n",
      "        0.88047138,  0.88383838,  0.88215488,  0.88552189,  0.88552189,\n",
      "        0.85521886,  0.85690236,  0.87037037,  0.86700337,  0.87037037,\n",
      "        0.85521886,  0.85690236,  0.87037037,  0.86700337,  0.87037037,\n",
      "        0.85521886,  0.85690236,  0.87037037,  0.86700337,  0.87037037,\n",
      "        0.85521886,  0.85690236,  0.87037037,  0.86700337,  0.87037037,\n",
      "        0.85521886,  0.85690236,  0.87037037,  0.86700337,  0.87037037]), 'split1_train_score': array([ 0.99326599,  0.996633  ,  0.996633  ,  0.996633  ,  0.996633  ,\n",
      "        0.96464646,  0.96127946,  0.95959596,  0.96296296,  0.96127946,\n",
      "        0.91077441,  0.91245791,  0.91582492,  0.91582492,  0.91582492,\n",
      "        0.89057239,  0.8973064 ,  0.9023569 ,  0.9040404 ,  0.90572391,\n",
      "        0.88047138,  0.88888889,  0.89225589,  0.89225589,  0.89393939,\n",
      "        0.87542088,  0.88047138,  0.87373737,  0.87373737,  0.87542088,\n",
      "        0.87542088,  0.88047138,  0.87373737,  0.87373737,  0.87542088,\n",
      "        0.87542088,  0.88047138,  0.87373737,  0.87373737,  0.87542088,\n",
      "        0.86868687,  0.86531987,  0.87037037,  0.86531987,  0.86868687,\n",
      "        0.85690236,  0.86026936,  0.86531987,  0.86363636,  0.86531987,\n",
      "        0.83333333,  0.83164983,  0.82996633,  0.82996633,  0.82996633,\n",
      "        0.83333333,  0.83164983,  0.82996633,  0.82996633,  0.82996633,\n",
      "        0.83333333,  0.83164983,  0.82996633,  0.82996633,  0.82996633,\n",
      "        0.83333333,  0.83164983,  0.82996633,  0.82996633,  0.82996633,\n",
      "        0.83333333,  0.83164983,  0.82996633,  0.82996633,  0.82996633,\n",
      "        0.99326599,  0.996633  ,  0.996633  ,  0.996633  ,  0.996633  ,\n",
      "        0.96464646,  0.96464646,  0.96464646,  0.96464646,  0.96632997,\n",
      "        0.90740741,  0.90909091,  0.91582492,  0.91414141,  0.91414141,\n",
      "        0.90572391,  0.9040404 ,  0.91245791,  0.91245791,  0.90909091,\n",
      "        0.88720539,  0.88888889,  0.8956229 ,  0.89393939,  0.8956229 ,\n",
      "        0.86868687,  0.87037037,  0.87373737,  0.87037037,  0.87205387,\n",
      "        0.86868687,  0.87037037,  0.87373737,  0.87037037,  0.87205387,\n",
      "        0.86868687,  0.87037037,  0.87373737,  0.87037037,  0.87205387,\n",
      "        0.87037037,  0.87037037,  0.87205387,  0.86531987,  0.87037037,\n",
      "        0.86363636,  0.85690236,  0.86531987,  0.86363636,  0.86868687,\n",
      "        0.83333333,  0.83670034,  0.83164983,  0.82996633,  0.82996633,\n",
      "        0.83333333,  0.83670034,  0.83164983,  0.82996633,  0.82996633,\n",
      "        0.83333333,  0.83670034,  0.83164983,  0.82996633,  0.82996633,\n",
      "        0.83333333,  0.83670034,  0.83164983,  0.82996633,  0.82996633,\n",
      "        0.83333333,  0.83670034,  0.83164983,  0.82996633,  0.82996633]), 'split2_train_score': array([ 1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        0.95622896,  0.95622896,  0.95454545,  0.95454545,  0.95286195,\n",
      "        0.8989899 ,  0.9023569 ,  0.8989899 ,  0.9006734 ,  0.8989899 ,\n",
      "        0.88888889,  0.88215488,  0.88888889,  0.89225589,  0.89393939,\n",
      "        0.87878788,  0.87710438,  0.88047138,  0.87710438,  0.87542088,\n",
      "        0.86026936,  0.85690236,  0.85858586,  0.85858586,  0.85858586,\n",
      "        0.86026936,  0.85690236,  0.85858586,  0.85858586,  0.85858586,\n",
      "        0.86026936,  0.85690236,  0.85858586,  0.85858586,  0.85858586,\n",
      "        0.85858586,  0.85858586,  0.85858586,  0.85690236,  0.85858586,\n",
      "        0.85690236,  0.85690236,  0.85858586,  0.85858586,  0.85690236,\n",
      "        0.84680135,  0.84175084,  0.83670034,  0.83838384,  0.83838384,\n",
      "        0.84680135,  0.84175084,  0.83670034,  0.83838384,  0.83838384,\n",
      "        0.84680135,  0.84175084,  0.83670034,  0.83838384,  0.83838384,\n",
      "        0.84680135,  0.84175084,  0.83670034,  0.83838384,  0.83838384,\n",
      "        0.84680135,  0.84175084,  0.83670034,  0.83838384,  0.83838384,\n",
      "        1.        ,  1.        ,  1.        ,  1.        ,  1.        ,\n",
      "        0.96296296,  0.96127946,  0.95454545,  0.96127946,  0.95622896,\n",
      "        0.8973064 ,  0.90572391,  0.9006734 ,  0.8989899 ,  0.9006734 ,\n",
      "        0.88383838,  0.89057239,  0.8956229 ,  0.8956229 ,  0.8973064 ,\n",
      "        0.88552189,  0.88215488,  0.87542088,  0.88383838,  0.88047138,\n",
      "        0.86195286,  0.85690236,  0.86026936,  0.86026936,  0.86026936,\n",
      "        0.86195286,  0.85690236,  0.86026936,  0.86026936,  0.86026936,\n",
      "        0.86195286,  0.85690236,  0.86026936,  0.86026936,  0.86026936,\n",
      "        0.86026936,  0.85521886,  0.85858586,  0.85690236,  0.85690236,\n",
      "        0.85690236,  0.85185185,  0.85690236,  0.85690236,  0.85690236,\n",
      "        0.84175084,  0.84006734,  0.84006734,  0.83838384,  0.84006734,\n",
      "        0.84175084,  0.84006734,  0.84006734,  0.83838384,  0.84006734,\n",
      "        0.84175084,  0.84006734,  0.84006734,  0.83838384,  0.84006734,\n",
      "        0.84175084,  0.84006734,  0.84006734,  0.83838384,  0.84006734,\n",
      "        0.84175084,  0.84006734,  0.84006734,  0.83838384,  0.84006734]), 'mean_train_score': array([ 0.99719416,  0.9983165 ,  0.9983165 ,  0.9983165 ,  0.9983165 ,\n",
      "        0.96352413,  0.96296296,  0.96127946,  0.9624018 ,  0.96184063,\n",
      "        0.90909091,  0.91301908,  0.91358025,  0.91358025,  0.91470258,\n",
      "        0.89674523,  0.89786756,  0.9023569 ,  0.90291807,  0.9040404 ,\n",
      "        0.88888889,  0.89169473,  0.89393939,  0.89225589,  0.89225589,\n",
      "        0.87317621,  0.87373737,  0.87205387,  0.87373737,  0.87373737,\n",
      "        0.87317621,  0.87373737,  0.87205387,  0.87373737,  0.87373737,\n",
      "        0.87317621,  0.87373737,  0.87205387,  0.87373737,  0.87373737,\n",
      "        0.8698092 ,  0.8681257 ,  0.8714927 ,  0.86924804,  0.8714927 ,\n",
      "        0.86251403,  0.86588103,  0.8681257 ,  0.86868687,  0.8681257 ,\n",
      "        0.84511785,  0.84399551,  0.84848485,  0.84848485,  0.84792368,\n",
      "        0.84511785,  0.84399551,  0.84848485,  0.84848485,  0.84792368,\n",
      "        0.84511785,  0.84399551,  0.84848485,  0.84848485,  0.84792368,\n",
      "        0.84511785,  0.84399551,  0.84848485,  0.84848485,  0.84792368,\n",
      "        0.84511785,  0.84399551,  0.84848485,  0.84848485,  0.84792368,\n",
      "        0.99719416,  0.9983165 ,  0.9983165 ,  0.9983165 ,  0.9983165 ,\n",
      "        0.9657688 ,  0.9657688 ,  0.9640853 ,  0.96632997,  0.96464646,\n",
      "        0.90740741,  0.91301908,  0.91470258,  0.91470258,  0.91470258,\n",
      "        0.89842873,  0.9023569 ,  0.90852974,  0.90909091,  0.90909091,\n",
      "        0.89225589,  0.89169473,  0.89281706,  0.8956229 ,  0.89450056,\n",
      "        0.87093154,  0.87205387,  0.87373737,  0.87205387,  0.87261504,\n",
      "        0.87093154,  0.87205387,  0.87373737,  0.87205387,  0.87261504,\n",
      "        0.87093154,  0.87205387,  0.87373737,  0.87205387,  0.87261504,\n",
      "        0.87093154,  0.87037037,  0.8714927 ,  0.86924804,  0.87037037,\n",
      "        0.86700337,  0.86419753,  0.8681257 ,  0.86868687,  0.87037037,\n",
      "        0.84343434,  0.84455668,  0.84736251,  0.84511785,  0.84680135,\n",
      "        0.84343434,  0.84455668,  0.84736251,  0.84511785,  0.84680135,\n",
      "        0.84343434,  0.84455668,  0.84736251,  0.84511785,  0.84680135,\n",
      "        0.84343434,  0.84455668,  0.84736251,  0.84511785,  0.84680135,\n",
      "        0.84343434,  0.84455668,  0.84736251,  0.84511785,  0.84680135]), 'std_train_score': array([ 0.0028614 ,  0.00137457,  0.00137457,  0.00137457,  0.00137457,\n",
      "        0.00555527,  0.00629909,  0.00629909,  0.00619829,  0.00757056,\n",
      "        0.0076533 ,  0.00894353,  0.01111054,  0.00975205,  0.01239659,\n",
      "        0.00994391,  0.01306447,  0.01099659,  0.00828553,  0.0076533 ,\n",
      "        0.01311259,  0.01320831,  0.01174436,  0.01237116,  0.01311259,\n",
      "        0.00975205,  0.01198325,  0.0103778 ,  0.01237116,  0.01174436,\n",
      "        0.00975205,  0.01198325,  0.0103778 ,  0.01237116,  0.01174436,\n",
      "        0.00975205,  0.01198325,  0.0103778 ,  0.01237116,  0.01174436,\n",
      "        0.00965469,  0.00915236,  0.01102519,  0.0120095 ,  0.01185113,\n",
      "        0.0079361 ,  0.0104081 ,  0.00915236,  0.01091034,  0.01049848,\n",
      "        0.00901368,  0.01111054,  0.02160312,  0.02052676,  0.01974479,\n",
      "        0.00901368,  0.01111054,  0.02160312,  0.02052676,  0.01974479,\n",
      "        0.00901368,  0.01111054,  0.02160312,  0.02052676,  0.01974479,\n",
      "        0.00901368,  0.01111054,  0.02160312,  0.02052676,  0.01974479,\n",
      "        0.00901368,  0.01111054,  0.02160312,  0.02052676,  0.01974479,\n",
      "        0.0028614 ,  0.00137457,  0.00137457,  0.00137457,  0.00137457,\n",
      "        0.0028614 ,  0.00419939,  0.00757056,  0.00495609,  0.00629909,\n",
      "        0.00824744,  0.00805426,  0.01102519,  0.01306447,  0.01169061,\n",
      "        0.01031693,  0.00901368,  0.00935653,  0.00991219,  0.00962201,\n",
      "        0.0083612 ,  0.00915236,  0.01320831,  0.0103778 ,  0.01102519,\n",
      "        0.00839878,  0.01311259,  0.01099659,  0.0103778 ,  0.01031693,\n",
      "        0.00839878,  0.01311259,  0.01099659,  0.0103778 ,  0.01031693,\n",
      "        0.00839878,  0.01311259,  0.01099659,  0.0103778 ,  0.01031693,\n",
      "        0.00894353,  0.01237116,  0.01031693,  0.0120095 ,  0.01099659,\n",
      "        0.00991219,  0.0140404 ,  0.01049848,  0.01221748,  0.01174436,\n",
      "        0.00901368,  0.00883727,  0.01662798,  0.01585235,  0.01716842,\n",
      "        0.00901368,  0.00883727,  0.01662798,  0.01585235,  0.01716842,\n",
      "        0.00901368,  0.00883727,  0.01662798,  0.01585235,  0.01716842,\n",
      "        0.00901368,  0.00883727,  0.01662798,  0.01585235,  0.01716842,\n",
      "        0.00901368,  0.00883727,  0.01662798,  0.01585235,  0.01716842])}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(max_features='auto', oob_score=True, random_state=1, n_jobs=-1)\n",
    "\n",
    "param_grid = { \"criterion\" : [\"gini\", \"entropy\"], \"min_samples_leaf\" : [1, 5, 10], \"min_samples_split\" : [2, 4, 10, 12, 16], \"n_estimators\": [50, 100, 400, 700, 1000]}\n",
    "\n",
    "gs = GridSearchCV(estimator=rf, param_grid=param_grid, scoring='accuracy', cv=3, n_jobs=-1)\n",
    "\n",
    "gs = gs.fit(train.iloc[:, 1:], train.iloc[:, 0])\n",
    "\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)\n",
    "print(gs.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our optimal parameters lie inside the hyperparameter specifications we outlined, so we can be confident that no further exploration will be required. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can fit our model with the hyperparameters outlined above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8294\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(criterion='gini', \n",
    "                             n_estimators=700,\n",
    "                             min_samples_split=10,\n",
    "                             min_samples_leaf=1,\n",
    "                             max_features='auto',\n",
    "                             oob_score=True,\n",
    "                             random_state=1,\n",
    "                             n_jobs=-1)\n",
    "rf.fit(train.iloc[:, 1:], train.iloc[:, 0])\n",
    "print(\"%.4f\" % rf.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a pretty good out of bag score, so now let's see what were the most important determinants in our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sex_female</td>\n",
       "      <td>0.111215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sex_male</td>\n",
       "      <td>0.109769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Name_Title_Mr.</td>\n",
       "      <td>0.109746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.088209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Name_Len</td>\n",
       "      <td>0.087904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age</td>\n",
       "      <td>0.078651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Pclass_3</td>\n",
       "      <td>0.043268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Name_Title_Miss.</td>\n",
       "      <td>0.031292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ticket_Len</td>\n",
       "      <td>0.031079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Name_Title_Mrs.</td>\n",
       "      <td>0.028852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Cabin_Letter_n</td>\n",
       "      <td>0.027893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Fam_Size_Big</td>\n",
       "      <td>0.025199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Fam_Size_Nuclear</td>\n",
       "      <td>0.022704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pclass_1</td>\n",
       "      <td>0.021810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Ticket_Lett_1</td>\n",
       "      <td>0.017999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Ticket_Lett_3</td>\n",
       "      <td>0.012902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Pclass_2</td>\n",
       "      <td>0.012345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Name_Title_Master.</td>\n",
       "      <td>0.012098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Ticket_Lett_Low_ticket</td>\n",
       "      <td>0.011723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Embarked_S</td>\n",
       "      <td>0.011546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  variable  importance\n",
       "12              Sex_female    0.111215\n",
       "11                Sex_male    0.109769\n",
       "33          Name_Title_Mr.    0.109746\n",
       "1                     Fare    0.088209\n",
       "2                 Name_Len    0.087904\n",
       "0                      Age    0.078651\n",
       "8                 Pclass_3    0.043268\n",
       "35        Name_Title_Miss.    0.031292\n",
       "7               Ticket_Len    0.031079\n",
       "34         Name_Title_Mrs.    0.028852\n",
       "25          Cabin_Letter_n    0.027893\n",
       "43            Fam_Size_Big    0.025199\n",
       "41        Fam_Size_Nuclear    0.022704\n",
       "9                 Pclass_1    0.021810\n",
       "19           Ticket_Lett_1    0.017999\n",
       "20           Ticket_Lett_3    0.012902\n",
       "10                Pclass_2    0.012345\n",
       "36      Name_Title_Master.    0.012098\n",
       "23  Ticket_Lett_Low_ticket    0.011723\n",
       "13              Embarked_S    0.011546"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat((pd.DataFrame(train.iloc[:, 1:].columns, columns = ['variable']), \n",
    "           pd.DataFrame(rf.feature_importances_, columns = ['importance'])), \n",
    "          axis = 1).sort_values(by='importance', ascending = False)[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:\\\\Users\\\\michael.clawson\\\\Desktop\\\\School\\\\Machine Learning\\\\Titanic\\\\Titanic_Kaggle_Submission.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-183-a4fbada8664e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:\\\\Users\\\\michael.clawson\\\\Desktop\\School\\\\Machine Learning\\\\Titanic\\\\test.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mpredictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:\\\\Users\\\\michael.clawson\\\\Desktop\\School\\\\Machine Learning\\\\Titanic\\\\Titanic_Kaggle_Submission.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[0;32m   1401\u001b[0m                                      \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1402\u001b[0m                                      escapechar=escapechar, decimal=decimal)\n\u001b[1;32m-> 1403\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1404\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1405\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1575\u001b[0m             f, handles = _get_handle(self.path_or_buf, self.mode,\n\u001b[0;32m   1576\u001b[0m                                      \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1577\u001b[1;33m                                      compression=self.compression)\n\u001b[0m\u001b[0;32m   1578\u001b[0m             \u001b[0mclose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m             \u001b[1;31m# Python 3 and no explicit encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'replace'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[1;31m# Python 3 and binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:\\\\Users\\\\michael.clawson\\\\Desktop\\\\School\\\\Machine Learning\\\\Titanic\\\\Titanic_Kaggle_Submission.csv'"
     ]
    }
   ],
   "source": [
    "predictions = rf.predict(test)\n",
    "predictions = pd.DataFrame(predictions, columns=['Survived'])\n",
    "test = pd.read_csv(os.path.join('C:\\\\Users\\\\michael.clawson\\\\Desktop\\School\\\\Machine Learning\\\\Titanic\\\\test.csv'))\n",
    "predictions = pd.concat([test.iloc[:, 0], predictions], axis = 1)\n",
    "predictions.to_csv('C:\\\\Users\\\\michael.clawson\\\\Desktop\\School\\\\Machine Learning\\\\Titanic\\\\Titanic_Kaggle_Submission.csv', sep=\",\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
